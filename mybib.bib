@online{icart_mini,
    author = "",
    title = "I-Cart mini",
    url  = " https://t-frog.com/products/icart_mini/",
    addendum = "(accessed: 20.11.2021)",
    keywords = "coex,clover"
}

@online{vlp16,
    author = "",
    title = "Velodyne Lidar",
    url  = " https://velodynelidar.com/products/puck/",
    addendum = "(accessed: 20.11.2021)",
    keywords = "coex,clover"
}


@article{legoloam,
  title = {LeGO-LOAM: Lightweight and GroundOptimized Lidar Odometry and Mapping on Variable Terrain},
  author= {T. Shan and B. Englot},
  journal={Proc. of International Conference on Intelligent Robots and Systems (IROS)},
  volume={},
  number={},
  pages={},
  year={2018},
  publisher={}
}

@article{loam,
author = {Zhang, Ji and Singh, Sanjiv},
year = {2014},
month = {01},
pages = {109-111},
title = {LOAM : Lidar Odometry and Mapping in real-time},
journal = {Robotics: Science and Systems Conference (RSS)}
}

@inproceedings{online_learning,
   author = {Zhi Yan and Tom Duckett and Nicola Bellotto},
   title = {Online learning for human classification in {3D LiDAR-based} tracking},
   booktitle = {Proceedings of the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
   pages = {864--871},
   address = {Vancouver, Canada},
   month = {9},
   year = {2017}
}


@INPROCEEDINGS{kidono,
  author={Kidono, Kiyosumi and Miyasaka, Takeo and Watanabe, Akihiro and Naito, Takashi and Miura, Jun},
  booktitle={2011 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={Pedestrian recognition using high-definition LIDAR}, 
  year={2011},
  volume={},
  number={},
  pages={405-410},
  doi={10.1109/IVS.2011.5940433}}
  
@Article{DL_Color_feature,
AUTHOR = {Algabri, Redhwan and Choi, Mun-Taek},
TITLE = {Deep-Learning-Based Indoor Human Following of Mobile Robot Using Color Feature},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {2699},
URL = {https://www.mdpi.com/1424-8220/20/9/2699},
ISSN = {1424-8220},
ABSTRACT = {Human following is one of the fundamental functions in human&ndash;robot interaction for mobile robots. This paper shows a novel framework with state-machine control in which the robot tracks the target person in occlusion and illumination changes, as well as navigates with obstacle avoidance while following the target to the destination. People are detected and tracked using a deep learning algorithm, called Single Shot MultiBox Detector, and the target person is identified by extracting the color feature using the hue-saturation-value histogram. The robot follows the target safely to the destination using a simultaneous localization and mapping algorithm with the LIDAR sensor for obstacle avoidance. We performed intensive experiments on our human following approach in an indoor environment with multiple people and moderate illumination changes. Experimental results indicated that the robot followed the target well to the destination, showing the effectiveness and practicability of our proposed system in the given environment.},
DOI = {10.3390/s20092699}
}

@INPROCEEDINGS{cnn_uav,
  author={Hayton, Jack N.C. and Barros, Tiago and Premebida, Cristiano and Coombes, Matthew J. and Nunes, Urbano J.},
  booktitle={2020 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC)}, 
  title={CNN-based Human Detection Using a 3D LiDAR onboard a UAV}, 
  year={2020},
  volume={},
  number={},
  pages={312-318},
  doi={10.1109/ICARSC49921.2020.9096075}}
  
  
@inproceedings{guide_svm,
   author = {Chih-Wei,Hsu and Chih-Chung,Chang and Chih-Jen,Lin},
   title = {A Practical Guide to Support Vector Classification},
   booktitle = {},
   pages = {},
   address = {Taipei, Taiwan},
   month = {5},
   year = {2016}
}

@inproceedings{libsvm,
   author = {Chih-Wei,Hsu and Chih-Chung,Chang and Chih-Jen,Lin},
   title = {LIBSVM: A library for support vector machines},
   booktitle = {ACM Transactions on Intelligent Systems and Technology},
   pages = {1-27},
   address = {},
   month = {},
   year = {2011}
}

@inproceedings{rusu_thesis,
   author = {R. B. Rusu},
   title = {Semantic 3D object maps for everyday manipulation
in human living environments},
   booktitle = {},
   pages = {},
   address = { Computer Science
department, Technische Universitaet Muenchen, Germany},
   month = {},
   year = {2009}
}


@conference{ros_original,
  added-at = {2012-04-26T10:09:53.000+0200},
  attachments = {http://www.willowgarage.com/sites/default/files/icraoss09-ROS.pdf},
  author = {Quigley, Morgan and Conley, Ken and Gerkey, Brian P. and Faust, Josh and Foote, Tully and Leibs, Jeremy and Wheeler, Rob and Ng, Andrew Y.},
  biburl = {https://www.bibsonomy.org/bibtex/2281f400bf541a0022e41ace75d9156ea/markusjordan88},
  booktitle = {ICRA Workshop on Open Source Software},
  interhash = {798c35d25081ba9e72118e983fe27639},
  intrahash = {281f400bf541a0022e41ace75d9156ea},
  keywords = {middleware open robot ros source},
  timestamp = {2012-09-04T12:15:20.000+0200},
  title = {ROS: an open-source Robot Operating System},
  year = 2009
}

@INPROCEEDINGS{tf_lib,
  author={Foote, Tully},
  booktitle={2013 IEEE Conference on Technologies for Practical Robot Applications (TePRA)}, 
  title={tf: The transform library}, 
  year={2013},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/TePRA.2013.6556373}}
  
@inproceedings{online_learning_2020,
   author = {Zhi Yan and Tom Duckett and Nicola Bellotto},
   title = {Online learning for 3D LiDAR-based human detection: experimental analysis of point cloud clustering and classification methods},
   booktitle = {Auton Robot},
   pages = {147–164},
   address = {},
   month = {},
   year = {2020}
}


@article{hfr_lrs,
title = {Development of Human Following Mobile Robot System Using Laser Range Scanner},
journal = {Procedia Computer Science},
volume = {76},
pages = {455-460},
year = {2015},
note = {2015 IEEE International Symposium on Robotics and Intelligent Sensors (IEEE IRIS2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.12.310},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915038119},
author = {Noriyuki Kawarazaki and Lucas Tetsuya Kuwae and Tadashi Yoshidome},
keywords = {Laser Range Scanner, Human Detection and Following, Mobile Robot, Human Robot Interaction},
abstract = {This paper discussed a human following mobile robot system using laser range scanner. The laser range scanner is very useful device for getting the environmental information around the robot. We developed the human detecting algorithm that the laser range scanner to detect the shins of the target person. When the laser range scanner scans the person's shin, the shape of the section of the shin shows parabola shape of the convex below. The mobile robot can detect and follow the target person based on the positions of both shins. Since the laser range scanner detects the obstacles, the system has the collision avoidance functions. The effectiveness of our system is demonstrated by several performance tests.}
}

@inproceedings{ransac,
   author = {M. Fischler and R. Bolles},
   title = {Random sample consensus: A paradigm
for model fitting with applications to image analysis and automated
cartography},
   booktitle = {Communications of the ACM},
   pages = {vol.24,no.6},
   address = {},
   month = {},
   year = {1981}
}

@book{probab_robot,
  title     = "Probabilistic robotics",
  author    = " S. Thrun and W. Burgard and D. Fox",
  year      = 2005,
  publisher = "MIT Press",
  address   = "America"
}

@book{3d_pc_analysis,
  title     = "3D Point Cloud Analysis",
  author    = " Shan,Liu and Min,Zhang and Pranav,Kadam and C.-C. Jay,Kuo",
  year      = 2021,
  publisher = "",
  address   = "",
  doi = {https://doi.org/10.1007/978-3-030-89180-0}
}

@inproceedings{narvano_2009,
   author = {L. E. Navarro-Serment and C. Mertz and M. Hebert},
   title = {Pedestrian detection and tracking using three-dimensional ladar data},
   booktitle = {Proceedings of the 7th Conference on Field and Service Robotics (FSR)},
   pages = {103-112},
   address = {},
   month = {},
   year = {2009}
}


@online{intro_1,
    author = "Uptin,Saiidi",
    title = "We tested out this hotel robot (and it wasn’t totally competent)",
    url  = " https://www.cnbc.com/2018/02/21/we-tested-out-this-hotel-robot-in-singaore.html",
    addendum = "(accessed: 15.6.2022)",
    keywords = ""
}

@online{intro_2,
    author = "Kim,Da-sol",
    title = "E-mart unveils autonomous shopping cart Eli for test run",
    url  = "https://m.koreaherald.com/view.php?ud=20180417000718",
    addendum = "(accessed: 15.6.2022)",
    keywords = ""
}

@online{intro_3,
    author = "Chris,Wright",
    title = "How Cleaning Robots are Supporting Airports During COVID-19",
    url  = "https://www.aviationpros.com/airports/airport-technology/article/21159420/how-cleaning-robots-are-supporting-airports-during-covid19",
    addendum = "(accessed: 15.6.2022)",
    keywords = ""
}

@online{ransac_1,
    author = "AJith,RaJ",
    title = "3D RANSAC Algorithm for Lidar PCD Segmentation",
    url  = "https://medium.com/@ajithraj_gangadharan/3d-ransac-algorithm-for-lidar-pcd-segmentation-315d2a51351",
    addendum = "(accessed: 15.6.2022)",
    keywords = ""
}

@INPROCEEDINGS{visionbased,
  author={Christian,Schlegel and J¨org,Illmann and Heiko,Jaberg and
Matthias,Schuster and Robert,W¨orz},
  booktitle={Proceedings of British Machine Vision Conference}, 
  title={Vision Based Person Tracking with a Mobile Robot}, 
  year={1998},
  volume={},
  number={},
  pages={},
  doi={10.5244/C.12.42}}

@INPROCEEDINGS{detectionbasedcolor,
  author={Li, Haojie and Zhao, Qijie and Li, Xianfa and Zhang, Xudong},
  booktitle={International Journal of Intelligent Robotics and Applications}, 
  title={Object detection based on color and shape features for service robot in semi-structured indoor environment}, 
  year={2019},
  volume={},
  number={},
  pages={},
  doi={https://doi.org/10.1007/s41315-019-00113-3}}

@INPROCEEDINGS{realtimetarget,
  author={Ren, Qimin and Zhao, Qingjie and Qi, Hui and Li, Lingrui},
  booktitle={2016 35th Chinese Control Conference (CCC)}, 
  title={Real-time target tracking system for person-following robot}, 
  year={2016},
  volume={},
  number={},
  pages={6160-6165},
  doi={10.1109/ChiCC.2016.7554324}}
  
@online{chapter1-1,
    author = "Maggie,Tillman",
    title = "Real-life robots that will make you think the future is now",
    url  = "https://www.pocket-lint.com/gadgets/news/134820-real-life-robots-that-will-make-you-think-the-future-is-now",
    addendum = "(accessed: 10.6.2022)",
    keywords = ""
}

@online{chapter1-2,
    author = "Alex,Moltzau",
    title = "AI, Sensors and Robotics",
    url  = "https://towardsdatascience.com/ai-sensors-and-robotics-882caae34df9?gi=59e5ca98650",
    addendum = "(accessed: 10.6.2022)",
    keywords = ""
}

@online{chapter1-3,
    author = "Autocrypt",
    title = "Camera, Radar and LiDAR: A Comparison of the Three Types of Sensors and Their Limitations",
    url  = "https://autocrypt.io/camera-radar-lidar-comparison-three-types-of-sensors/",
    addendum = "(accessed: 10.6.2022)",
    keywords = ""
}

@InProceedings{refchap2-fig1,
author="Chen, Bao Xin
and Sahdev, Raghavender
and Tsotsos, John K.",
editor="Liu, Ming
and Chen, Haoyao
and Vincze, Markus",
title="Integrating Stereo Vision with a CNN Tracker for a Person-Following Robot",
booktitle="Computer Vision Systems",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="300--313",
doi={10.1007/978-3-319-68345-4_27},
abstract="In this paper, we introduce a stereo vision based CNN tracker for a person following robot. The tracker is able to track a person in real-time using an online convolutional neural network. Our approach enables the robot to follow a target under challenging situations such as occlusions, appearance changes, pose changes, crouching, illumination changes or people wearing the same clothes in different environments. The robot follows the target around corners even when it is momentarily unseen by estimating and replicating the local path of the target. We build an extensive dataset for person following robots under challenging situations. We evaluate the proposed system quantitatively by comparing our tracking approach with existing real-time tracking algorithms.",
isbn="978-3-319-68345-4"
}

@article{fusionlidarandcamera,
title = {A survey of LiDAR and camera fusion enhancement},
journal = {Procedia Computer Science},
volume = {183},
pages = {579-588},
year = {2021},
note = {Proceedings of the 10th International Conference of Information and Communication Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.02.100},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921005767},
author = {Huazan Zhong and Hao Wang and Zhengrong Wu and Chen Zhang and Yongwei Zheng and Tao Tang},
keywords = {Fusion enhancement, Survey, KITTI, LiDAR, camera},
abstract = {Recently, two types of common sensors, LiDAR and Camera, show significant performance on all tasks in 3D vision. LiDAR provides accurate 3D geometry structure, while camera captures more scene context and semantic information. The fusion of two different sensor becomes a fundamental and common idea to achieve better performance. To give a thorough cognition of the complementary and boosting about two kind of sensors. This paper briefly reviews the fusion and enhancement systems between both two sensors in the field of depth completion, 3D object detection, 2D\3D semantic segmentation and 3D object tracking. Meanwhile, the state of art fusion algorithms is quantitatively demonstrated, in this paper, based on the in KITTI widely-used public dataset. Furthermore, the technical challenge and the future potential of LiDAR and camera fusion are also discussed.}
}

@INPROCEEDINGS{lspathplanning,  
author={Costa, Márcia M. and Silva, Manuel F.},  
booktitle={2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC)},   
title={A Survey on Path Planning Algorithms for Mobile Robots},   
year={2019},  
volume={},  
number={},  
pages={1-7},  
doi={10.1109/ICARSC.2019.8733623}}

@online{comparepidmpc,
    author = "Carnot,Innovations",
    title = "Model Predictive Control vs. Proportional, Integral, Derivative Control",
    url  = "https://www.carnot-innovations.com/post/model-predictive-control-vs-proportional-integral-derivative-control",
    addendum = "(accessed: 30.7.2022)",
    keywords = ""
}

@article{lidarproperties,
author = {Okunsky, M and Nesterova, N},
year = {2019},
month = {04},
pages = {012018},
title = {Velodyne LIDAR method for sensor data decoding},
volume = {516},
journal = {IOP Conference Series: Materials Science and Engineering},
doi = {10.1088/1757-899X/516/1/012018}
}

@online{calculateheight,
    author = "",
    title = "",
    url  = "https://robu.in/product/velodyne-puck-hi-res-lidar-sensor/",
    addendum = "(accessed: 30.7.2022)",
    keywords = ""
}

