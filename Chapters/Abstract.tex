% The abstract includes a summary of the main ideas developed in your dissertation. This section is the first one that is part of the main document and can be included with the \textit{$\backslash$input} command in the file \textbf{MainDocuments.tex}. To start a document, no tags are need. You can start writing straight away.

Human-following robots have emerged as a hot research topic in a variety of mobile robotics and computer vision applications because they have many practical applications such as personal airport guides, autonomous cars and surveillance systems. Human following is one of the most essential capabilities of mobile robots in human–robot interaction. Apart from apparent safety considerations, differentiating between humans and inanimate items gives additional information for the robot to plan and modify its future movement in the surroundings. To efficiently follow a specific person, the robot must be able to detect the target individual person within the surrounding indoor environment. In order to recognize human, numerous methods have been proposed such as RGB and RGB-D cameras and 2D LiDAR. Although the application of 3D LiDAR sensors in robotics field has also increased recently, there are still not so many researches has been conducted on 3D LiDAR-based human detection compared to that of RGB-D camera and 2D LiDAR. Moreover, human recognition in 3D LiDAR scans still remains difficult, particularly when the human is too close or too far away from the robot. Working with 3D LiDAR also presents the problem of detecting humans from a sparse number of points and without extra color information. Also, there is currently a lack of human dataset and model that make the classification part is tedious, especially when many variations of human pose, shape and size needed to be classified. 

In this thesis, based on many other previous researches, a pipeline to detect human in indoor environment will be proposed. In addition, planning and control system will also be integrated to make the mobile robot follow a specific person in that environment. Specifically, iCart-mini robot will be equipped with Velodyne VLP-16 3D LiDAR to detect and follow human. The pipeline will consist of several stages, including using 3D SLAM algorithms for synchronizing the raw data point cloud obtained from the LiDAR, ground detection and clustering. For the classification section, a online learning SVM-based method will be used along with built dataset. The pipeline will be implemented in ROS framework with the help of PCL library. A simulation model of iCart-mini mobile robot with Velodyne LiDAR will be constructed in Gazebo environment for debugging and testing. To navigate the robot to the human’s position, PID controller will be used to reduce the error distance between the robot position and target position. Data obtaining from simulation results will be compared with real experiment data collected in the indoor environment. Final results will be evaluated based on ROC curve and successful tracking rate and computation time. 